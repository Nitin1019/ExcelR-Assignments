{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\nitin\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\nitin\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nitin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gt=pd.read_csv(\"D:\\\\ExcelR_Assig_PDF\\\\Neural Networks\\\\gas_turbines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "Gt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x21ac4310cc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=\"CDP\",y=\"TEY\",data=Gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ac43a4408>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=Gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 247., 2671.,  474.,  528., 7145.,  462.,  989., 1215., 1160.,\n",
       "         148.]),\n",
       " array([100.17 , 107.614, 115.058, 122.502, 129.946, 137.39 , 144.834,\n",
       "        152.278, 159.722, 167.166, 174.61 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Gt['TEY']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_Gt=scaler.fit_transform(Gt)\n",
    "df=pd.DataFrame(standardized_Gt, columns=Gt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.439778</td>\n",
       "      <td>-0.826644</td>\n",
       "      <td>1.281436</td>\n",
       "      <td>-0.921232</td>\n",
       "      <td>-1.379101</td>\n",
       "      <td>-1.488376</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.231172</td>\n",
       "      <td>-1.357331</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>1.387845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.449601</td>\n",
       "      <td>-0.748647</td>\n",
       "      <td>1.304564</td>\n",
       "      <td>-0.921495</td>\n",
       "      <td>-1.363528</td>\n",
       "      <td>-1.482325</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.363676</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.393002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.434721</td>\n",
       "      <td>-0.686250</td>\n",
       "      <td>1.219086</td>\n",
       "      <td>-0.944385</td>\n",
       "      <td>-1.351309</td>\n",
       "      <td>-1.476275</td>\n",
       "      <td>0.568715</td>\n",
       "      <td>-1.230541</td>\n",
       "      <td>-1.360957</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>1.363586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.413702</td>\n",
       "      <td>-0.623853</td>\n",
       "      <td>1.169060</td>\n",
       "      <td>-0.946884</td>\n",
       "      <td>-1.348194</td>\n",
       "      <td>-1.464173</td>\n",
       "      <td>0.583969</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.356424</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>1.382878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368693</td>\n",
       "      <td>-0.545857</td>\n",
       "      <td>1.161883</td>\n",
       "      <td>-0.924389</td>\n",
       "      <td>-1.354663</td>\n",
       "      <td>-1.458123</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.350985</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>1.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>-1.153182</td>\n",
       "      <td>-1.185428</td>\n",
       "      <td>1.401860</td>\n",
       "      <td>-0.865850</td>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-2.063184</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>-1.426381</td>\n",
       "      <td>-1.543161</td>\n",
       "      <td>1.145792</td>\n",
       "      <td>1.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>-1.303986</td>\n",
       "      <td>-1.138630</td>\n",
       "      <td>1.447753</td>\n",
       "      <td>-0.913470</td>\n",
       "      <td>-1.438759</td>\n",
       "      <td>-2.268905</td>\n",
       "      <td>-0.276638</td>\n",
       "      <td>-1.415642</td>\n",
       "      <td>-1.513247</td>\n",
       "      <td>1.293578</td>\n",
       "      <td>1.119943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>-1.386267</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>1.476971</td>\n",
       "      <td>-0.951488</td>\n",
       "      <td>-1.410967</td>\n",
       "      <td>-2.789257</td>\n",
       "      <td>-1.026650</td>\n",
       "      <td>-1.516089</td>\n",
       "      <td>-1.467922</td>\n",
       "      <td>2.695925</td>\n",
       "      <td>2.170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>-1.420423</td>\n",
       "      <td>-0.998236</td>\n",
       "      <td>1.441590</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-1.447624</td>\n",
       "      <td>-2.456474</td>\n",
       "      <td>-0.528337</td>\n",
       "      <td>-1.481343</td>\n",
       "      <td>-1.422598</td>\n",
       "      <td>1.924683</td>\n",
       "      <td>2.391165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>-1.430734</td>\n",
       "      <td>-0.935839</td>\n",
       "      <td>1.334652</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-1.464635</td>\n",
       "      <td>-2.051083</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>-1.428277</td>\n",
       "      <td>-1.377273</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>2.321539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
       "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
       "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
       "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
       "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
       "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
       "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
       "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
       "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
       "\n",
       "            TEY       CDP        CO       NOX  \n",
       "0     -1.231172 -1.357331  0.532012  1.387845  \n",
       "1     -1.229909 -1.363676  0.568733  1.393002  \n",
       "2     -1.230541 -1.360957  0.552938  1.363586  \n",
       "3     -1.229909 -1.356424  0.548933  1.382878  \n",
       "4     -1.229909 -1.350985  0.574179  1.348591  \n",
       "...         ...       ...       ...       ...  \n",
       "15034 -1.426381 -1.543161  1.145792  1.085751  \n",
       "15035 -1.415642 -1.513247  1.293578  1.119943  \n",
       "15036 -1.516089 -1.467922  2.695925  2.170062  \n",
       "15037 -1.481343 -1.422598  1.924683  2.391165  \n",
       "15038 -1.428277 -1.377273  1.354150  2.321539  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.320107e-16</td>\n",
       "      <td>-1.925280e-14</td>\n",
       "      <td>1.844983e-16</td>\n",
       "      <td>3.810001e-16</td>\n",
       "      <td>1.107344e-16</td>\n",
       "      <td>-2.324212e-15</td>\n",
       "      <td>1.744899e-15</td>\n",
       "      <td>1.406445e-15</td>\n",
       "      <td>3.640356e-16</td>\n",
       "      <td>1.953355e-17</td>\n",
       "      <td>-6.862579e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.276462e+00</td>\n",
       "      <td>-4.266288e+00</td>\n",
       "      <td>-3.536594e+00</td>\n",
       "      <td>-2.779497e+00</td>\n",
       "      <td>-1.806771e+00</td>\n",
       "      <td>-5.021933e+00</td>\n",
       "      <td>-4.188141e+00</td>\n",
       "      <td>-2.149097e+00</td>\n",
       "      <td>-1.992416e+00</td>\n",
       "      <td>-8.874862e-01</td>\n",
       "      <td>-3.861033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.392292e-01</td>\n",
       "      <td>-6.706510e-01</td>\n",
       "      <td>-6.796337e-01</td>\n",
       "      <td>-6.266930e-01</td>\n",
       "      <td>-5.091458e-01</td>\n",
       "      <td>-2.540512e-01</td>\n",
       "      <td>-4.101146e-01</td>\n",
       "      <td>-3.919003e-01</td>\n",
       "      <td>-4.354335e-01</td>\n",
       "      <td>-5.015202e-01</td>\n",
       "      <td>-6.578107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.566605e-02</td>\n",
       "      <td>-6.227861e-02</td>\n",
       "      <td>2.277844e-01</td>\n",
       "      <td>-1.854065e-02</td>\n",
       "      <td>-8.075681e-02</td>\n",
       "      <td>2.965544e-01</td>\n",
       "      <td>5.712570e-01</td>\n",
       "      <td>-2.580448e-02</td>\n",
       "      <td>-7.011925e-02</td>\n",
       "      <td>-2.620452e-01</td>\n",
       "      <td>-1.518527e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.051309e-01</td>\n",
       "      <td>5.772924e-01</td>\n",
       "      <td>7.916582e-01</td>\n",
       "      <td>4.612196e-01</td>\n",
       "      <td>4.228638e-01</td>\n",
       "      <td>7.382490e-01</td>\n",
       "      <td>5.928675e-01</td>\n",
       "      <td>4.236815e-01</td>\n",
       "      <td>4.311680e-01</td>\n",
       "      <td>8.455882e-02</td>\n",
       "      <td>5.486567e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.266234e+00</td>\n",
       "      <td>3.275970e+00</td>\n",
       "      <td>1.528011e+00</td>\n",
       "      <td>4.486233e+00</td>\n",
       "      <td>2.871006e+00</td>\n",
       "      <td>1.028678e+00</td>\n",
       "      <td>6.627839e-01</td>\n",
       "      <td>2.553607e+00</td>\n",
       "      <td>2.700105e+00</td>\n",
       "      <td>1.895949e+01</td>\n",
       "      <td>4.937717e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT            AP            AH          AFDP          GTEP  \\\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04   \n",
       "mean  -2.320107e-16 -1.925280e-14  1.844983e-16  3.810001e-16  1.107344e-16   \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00   \n",
       "min   -2.276462e+00 -4.266288e+00 -3.536594e+00 -2.779497e+00 -1.806771e+00   \n",
       "25%   -8.392292e-01 -6.706510e-01 -6.796337e-01 -6.266930e-01 -5.091458e-01   \n",
       "50%    5.566605e-02 -6.227861e-02  2.277844e-01 -1.854065e-02 -8.075681e-02   \n",
       "75%    8.051309e-01  5.772924e-01  7.916582e-01  4.612196e-01  4.228638e-01   \n",
       "max    2.266234e+00  3.275970e+00  1.528011e+00  4.486233e+00  2.871006e+00   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04   \n",
       "mean  -2.324212e-15  1.744899e-15  1.406445e-15  3.640356e-16  1.953355e-17   \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00   \n",
       "min   -5.021933e+00 -4.188141e+00 -2.149097e+00 -1.992416e+00 -8.874862e-01   \n",
       "25%   -2.540512e-01 -4.101146e-01 -3.919003e-01 -4.354335e-01 -5.015202e-01   \n",
       "50%    2.965544e-01  5.712570e-01 -2.580448e-02 -7.011925e-02 -2.620452e-01   \n",
       "75%    7.382490e-01  5.928675e-01  4.236815e-01  4.311680e-01  8.455882e-02   \n",
       "max    1.028678e+00  6.627839e-01  2.553607e+00  2.700105e+00  1.895949e+01   \n",
       "\n",
       "                NOX  \n",
       "count  1.503900e+04  \n",
       "mean  -6.862579e-17  \n",
       "std    1.000033e+00  \n",
       "min   -3.861033e+00  \n",
       "25%   -6.578107e-01  \n",
       "50%   -1.518527e-01  \n",
       "75%    5.486567e-01  \n",
       "max    4.937717e+00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop([\"TEY\"],axis=1)\n",
    "y=df[\"TEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.439778</td>\n",
       "      <td>-0.826644</td>\n",
       "      <td>1.281436</td>\n",
       "      <td>-0.921232</td>\n",
       "      <td>-1.379101</td>\n",
       "      <td>-1.488376</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.357331</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>1.387845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.449601</td>\n",
       "      <td>-0.748647</td>\n",
       "      <td>1.304564</td>\n",
       "      <td>-0.921495</td>\n",
       "      <td>-1.363528</td>\n",
       "      <td>-1.482325</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.363676</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.393002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.434721</td>\n",
       "      <td>-0.686250</td>\n",
       "      <td>1.219086</td>\n",
       "      <td>-0.944385</td>\n",
       "      <td>-1.351309</td>\n",
       "      <td>-1.476275</td>\n",
       "      <td>0.568715</td>\n",
       "      <td>-1.360957</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>1.363586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.413702</td>\n",
       "      <td>-0.623853</td>\n",
       "      <td>1.169060</td>\n",
       "      <td>-0.946884</td>\n",
       "      <td>-1.348194</td>\n",
       "      <td>-1.464173</td>\n",
       "      <td>0.583969</td>\n",
       "      <td>-1.356424</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>1.382878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368693</td>\n",
       "      <td>-0.545857</td>\n",
       "      <td>1.161883</td>\n",
       "      <td>-0.924389</td>\n",
       "      <td>-1.354663</td>\n",
       "      <td>-1.458123</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>-1.350985</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>1.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>-1.153182</td>\n",
       "      <td>-1.185428</td>\n",
       "      <td>1.401860</td>\n",
       "      <td>-0.865850</td>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-2.063184</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>-1.543161</td>\n",
       "      <td>1.145792</td>\n",
       "      <td>1.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>-1.303986</td>\n",
       "      <td>-1.138630</td>\n",
       "      <td>1.447753</td>\n",
       "      <td>-0.913470</td>\n",
       "      <td>-1.438759</td>\n",
       "      <td>-2.268905</td>\n",
       "      <td>-0.276638</td>\n",
       "      <td>-1.513247</td>\n",
       "      <td>1.293578</td>\n",
       "      <td>1.119943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>-1.386267</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>1.476971</td>\n",
       "      <td>-0.951488</td>\n",
       "      <td>-1.410967</td>\n",
       "      <td>-2.789257</td>\n",
       "      <td>-1.026650</td>\n",
       "      <td>-1.467922</td>\n",
       "      <td>2.695925</td>\n",
       "      <td>2.170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>-1.420423</td>\n",
       "      <td>-0.998236</td>\n",
       "      <td>1.441590</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-1.447624</td>\n",
       "      <td>-2.456474</td>\n",
       "      <td>-0.528337</td>\n",
       "      <td>-1.422598</td>\n",
       "      <td>1.924683</td>\n",
       "      <td>2.391165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>-1.430734</td>\n",
       "      <td>-0.935839</td>\n",
       "      <td>1.334652</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-1.464635</td>\n",
       "      <td>-2.051083</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>-1.377273</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>2.321539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
       "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
       "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
       "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
       "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
       "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
       "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
       "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
       "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
       "\n",
       "            CDP        CO       NOX  \n",
       "0     -1.357331  0.532012  1.387845  \n",
       "1     -1.363676  0.568733  1.393002  \n",
       "2     -1.360957  0.552938  1.363586  \n",
       "3     -1.356424  0.548933  1.382878  \n",
       "4     -1.350985  0.574179  1.348591  \n",
       "...         ...       ...       ...  \n",
       "15034 -1.543161  1.145792  1.085751  \n",
       "15035 -1.513247  1.293578  1.119943  \n",
       "15036 -1.467922  2.695925  2.170062  \n",
       "15037 -1.422598  1.924683  2.391165  \n",
       "15038 -1.377273  1.354150  2.321539  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -1.231172\n",
       "1       -1.229909\n",
       "2       -1.230541\n",
       "3       -1.229909\n",
       "4       -1.229909\n",
       "           ...   \n",
       "15034   -1.426381\n",
       "15035   -1.415642\n",
       "15036   -1.516089\n",
       "15037   -1.481343\n",
       "15038   -1.428277\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features =X.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=n_features, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    optmizer =RMSprop(0.03)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optmizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n",
      "[CV] ............ batch_size=10, epochs=10, score=0.000, total=  22.6s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.000, total=  20.2s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   42.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.000, total=  19.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.000, total=  19.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.000, total=  24.1s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.000, total= 1.6min\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.000, total= 1.6min\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  5.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.000, total= 1.8min\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  6.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.000, total= 1.7min\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  8.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.000, total= 1.8min\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.000, total= 3.1min\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.000, total= 2.9min\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.000, total= 2.8min\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.000, total= 3.1min\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.000, total= 3.5min\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.000, total=  14.9s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.000, total=  14.2s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.000, total=  10.8s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.000, total=  17.0s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.000, total=  17.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.000, total= 1.2min\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.000, total=  55.1s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.000, total=  54.6s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.000, total=  53.9s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.000, total= 1.1min\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.000, total= 1.5min\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.000, total= 1.5min\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.000, total= 1.5min\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.000, total= 1.5min\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.000, total= 1.4min\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.000, total=   5.8s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.000, total=   5.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.000, total=   5.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.000, total=   5.7s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.000, total=   5.7s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.000, total=  23.5s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.000, total=  23.3s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.000, total=  23.4s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.000, total=  22.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.000, total=  23.5s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.000, total=  46.4s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.000, total= 1.1min\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.000, total= 1.1min\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.000, total= 1.3min\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.000, total=  52.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 46.9min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}'.format(mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = n_features,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = n_features,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss='mean_squared_error',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.000, total=  23.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.9s remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.000, total=  21.3s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   44.1s remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.000, total=  21.5s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.1min remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.000, total=  21.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.000, total=  19.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.000, total=  19.2s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.1min remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.000, total=  20.2s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.4min remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.000, total=  19.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.8min remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.000, total=  19.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.1min remaining:    0.0s\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.000, total=  20.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.000, total=  21.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.000, total=  22.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.000, total=  19.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.000, total=  19.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.000, total=  19.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.000, total=  22.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.000, total=  20.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.000, total=  20.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.000, total=  20.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.000, total=  20.5s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.000, total=  21.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.000, total=  21.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.000, total=  20.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.000, total=  21.5s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.000, total=  24.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.000, total=  20.8s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.000, total=  20.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.000, total=  20.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.000, total=  20.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.000, total=  19.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.000, total=  19.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.000, total=  20.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.000, total=  19.7s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.000, total=  19.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.000, total=  21.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.000, total=  19.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.000, total=  22.5s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.000, total=  22.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.000, total=  17.1s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.000, total=   7.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.000, total=   8.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.000, total=   8.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.000, total=   8.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.000, total=   7.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.000, total=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 14.2min finished\n",
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = n_features,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    optmizer =RMSprop(0.001)#here,Learning_rate is 0.03\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=2, score=0.000, total=  10.5s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   18.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.000, total=   8.3s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   34.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.000, total=  10.8s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   45.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.000, total=   9.2s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   54.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.000, total=   9.7s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.000, total=   9.0s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.000, total=   8.9s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.000, total=   9.4s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.000, total=   8.2s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.000, total=   8.2s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.000, total=   8.3s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.000, total=   8.0s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.000, total=   8.0s\n",
      "[CV] neuron1=4, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=30, score=0.000, total=   8.5s\n",
      "[CV] neuron1=4, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=30, score=0.000, total=   8.2s\n",
      "[CV] neuron1=4, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=30, score=0.000, total=   8.0s\n",
      "[CV] neuron1=4, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=40, score=0.000, total=   8.0s\n",
      "[CV] neuron1=4, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=40, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=40, score=0.000, total=   9.0s\n",
      "[CV] neuron1=4, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=40, score=0.000, total=   8.2s\n",
      "[CV] neuron1=4, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=40, score=0.000, total=   8.4s\n",
      "[CV] neuron1=4, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=50, score=0.000, total=   8.3s\n",
      "[CV] neuron1=4, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=50, score=0.000, total=   8.3s\n",
      "[CV] neuron1=4, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=50, score=0.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=50, score=0.000, total=   8.4s\n",
      "[CV] neuron1=4, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=50, score=0.000, total=   8.3s\n",
      "[CV] neuron1=4, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=60, score=0.000, total=   8.3s\n",
      "[CV] neuron1=4, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=60, score=0.000, total=   8.2s\n",
      "[CV] neuron1=4, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=60, score=0.000, total=   8.4s\n",
      "[CV] neuron1=4, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=60, score=0.000, total=   8.2s\n",
      "[CV] neuron1=4, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=4, neuron2=60, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.000, total=   8.2s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.000, total=  18.8s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.000, total=   8.2s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.000, total=   8.5s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.000, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.000, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.000, total=   8.2s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.000, total=   8.2s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.000, total=   8.2s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.000, total=   8.6s\n",
      "[CV] neuron1=8, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=20, score=0.000, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=20 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=20, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=30, score=0.000, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=30 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=40, score=0.000, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=40, score=0.000, total=   8.2s\n",
      "[CV] neuron1=8, neuron2=40 ...........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... neuron1=8, neuron2=40, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=40, score=0.000, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=40 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=40, score=0.000, total=   9.0s\n",
      "[CV] neuron1=8, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=50, score=0.000, total=  10.5s\n",
      "[CV] neuron1=8, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=50, score=0.000, total=   8.7s\n",
      "[CV] neuron1=8, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=50, score=0.000, total=   9.5s\n",
      "[CV] neuron1=8, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=50, score=0.000, total=   8.8s\n",
      "[CV] neuron1=8, neuron2=50 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=50, score=0.000, total=   8.4s\n",
      "[CV] neuron1=8, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=60, score=0.000, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=60, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=60, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=60, score=0.000, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=60 ...........................................\n",
      "[CV] ............... neuron1=8, neuron2=60, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.000, total=   8.4s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.000, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.000, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.000, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.000, total=   8.4s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.000, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=20, score=0.000, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=20, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=20, score=0.000, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=20, score=0.000, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=20, score=0.000, total=   8.3s\n",
      "[CV] neuron1=16, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=30, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=30, score=0.000, total=   8.6s\n",
      "[CV] neuron1=16, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=30, score=0.000, total=  11.7s\n",
      "[CV] neuron1=16, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=40, score=0.000, total=   9.7s\n",
      "[CV] neuron1=16, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=40, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=40, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=40, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=40, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=50, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=50, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=50, score=0.000, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=50, score=0.000, total=   8.3s\n",
      "[CV] neuron1=16, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=50, score=0.000, total=   8.3s\n",
      "[CV] neuron1=16, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=60, score=0.000, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=60, score=0.000, total=   8.4s\n",
      "[CV] neuron1=16, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=60, score=0.000, total=   9.1s\n",
      "[CV] neuron1=16, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=60, score=0.000, total=   8.9s\n",
      "[CV] neuron1=16, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=16, neuron2=60, score=0.000, total=   8.9s\n",
      "[CV] neuron1=20, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=2, score=0.000, total=   9.2s\n",
      "[CV] neuron1=20, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=2, score=0.000, total=  10.4s\n",
      "[CV] neuron1=20, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=2, score=0.000, total=  10.0s\n",
      "[CV] neuron1=20, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=2, score=0.000, total=   8.9s\n",
      "[CV] neuron1=20, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=2, score=0.000, total=   8.9s\n",
      "[CV] neuron1=20, neuron2=4 ...........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... neuron1=20, neuron2=4, score=0.000, total=   9.1s\n",
      "[CV] neuron1=20, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=4, score=0.000, total=   8.5s\n",
      "[CV] neuron1=20, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=4, score=0.000, total=   9.0s\n",
      "[CV] neuron1=20, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=4, score=0.000, total=   8.2s\n",
      "[CV] neuron1=20, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=4, score=0.000, total=   8.1s\n",
      "[CV] neuron1=20, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=8, score=0.000, total=   8.1s\n",
      "[CV] neuron1=20, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=8, score=0.000, total=   8.3s\n",
      "[CV] neuron1=20, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=8, score=0.000, total=   8.1s\n",
      "[CV] neuron1=20, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=8, score=0.000, total=   7.6s\n",
      "[CV] neuron1=20, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=20, neuron2=8, score=0.000, total=   8.0s\n",
      "[CV] neuron1=20, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=20, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=20, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=20, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=20, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=20, score=0.000, total=   7.9s\n",
      "[CV] neuron1=20, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=30, score=0.000, total=   8.0s\n",
      "[CV] neuron1=20, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=30, score=0.000, total=   7.9s\n",
      "[CV] neuron1=20, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=30, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=30, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=30, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=40, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=40, score=0.000, total=   7.9s\n",
      "[CV] neuron1=20, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=40, score=0.000, total=   7.9s\n",
      "[CV] neuron1=20, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=40, score=0.000, total=   7.9s\n",
      "[CV] neuron1=20, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=40, score=0.000, total=   7.9s\n",
      "[CV] neuron1=20, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=50, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=50, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=50, score=0.000, total=   7.6s\n",
      "[CV] neuron1=20, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=50, score=0.000, total=   7.6s\n",
      "[CV] neuron1=20, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=50, score=0.000, total=   7.7s\n",
      "[CV] neuron1=20, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=60, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=60, score=0.000, total=   7.8s\n",
      "[CV] neuron1=20, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=60, score=0.000, total=   7.7s\n",
      "[CV] neuron1=20, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=60, score=0.000, total=   7.7s\n",
      "[CV] neuron1=20, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=20, neuron2=60, score=0.000, total=   7.7s\n",
      "[CV] neuron1=30, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=2, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=2, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=2, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=2, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=2, score=0.000, total=   7.8s\n",
      "[CV] neuron1=30, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=4, score=0.000, total=   7.8s\n",
      "[CV] neuron1=30, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=4, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=4, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=4, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=4, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=8, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=8, score=0.000, total=   7.7s\n",
      "[CV] neuron1=30, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=8, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=8, score=0.000, total=   7.8s\n",
      "[CV] neuron1=30, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=30, neuron2=8, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=20, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=20, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=20, score=0.000, total=   7.7s\n",
      "[CV] neuron1=30, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=20, score=0.000, total=   7.7s\n",
      "[CV] neuron1=30, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=20, score=0.000, total=   8.2s\n",
      "[CV] neuron1=30, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=30, score=0.000, total=   8.2s\n",
      "[CV] neuron1=30, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=30, score=0.000, total=   8.2s\n",
      "[CV] neuron1=30, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=30, score=0.000, total=   8.2s\n",
      "[CV] neuron1=30, neuron2=30 ..........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=30, neuron2=30, score=0.000, total=   8.0s\n",
      "[CV] neuron1=30, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=30, score=0.000, total=   7.9s\n",
      "[CV] neuron1=30, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=40, score=0.000, total=   7.8s\n",
      "[CV] neuron1=30, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=40, score=0.000, total=   7.7s\n",
      "[CV] neuron1=30, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=40, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=40, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=40, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=50, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=50, score=0.000, total=   7.7s\n",
      "[CV] neuron1=30, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=50, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=50, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=50, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=60, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=60, score=0.000, total=   7.6s\n",
      "[CV] neuron1=30, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=60, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=60, score=0.000, total=   7.5s\n",
      "[CV] neuron1=30, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=30, neuron2=60, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=2, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=2, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=2, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=2, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=2, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=4, score=0.000, total=   8.0s\n",
      "[CV] neuron1=40, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=4, score=0.000, total=   8.1s\n",
      "[CV] neuron1=40, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=4, score=0.000, total=   7.9s\n",
      "[CV] neuron1=40, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=4, score=0.000, total=   7.9s\n",
      "[CV] neuron1=40, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=4, score=0.000, total=   7.9s\n",
      "[CV] neuron1=40, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=8, score=0.000, total=   7.8s\n",
      "[CV] neuron1=40, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=8, score=0.000, total=   7.8s\n",
      "[CV] neuron1=40, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=8, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=8, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=40, neuron2=8, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=20, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=20, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=20, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=20, score=0.000, total=   7.7s\n",
      "[CV] neuron1=40, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=20, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=30, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=30, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=30, score=0.000, total=   7.7s\n",
      "[CV] neuron1=40, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=30, score=0.000, total=   7.7s\n",
      "[CV] neuron1=40, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=30, score=0.000, total=   7.7s\n",
      "[CV] neuron1=40, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=40, score=0.000, total=   7.8s\n",
      "[CV] neuron1=40, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=40, score=0.000, total=   7.9s\n",
      "[CV] neuron1=40, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=40, score=0.000, total=   8.0s\n",
      "[CV] neuron1=40, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=40, score=0.000, total=   8.1s\n",
      "[CV] neuron1=40, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=40, score=0.000, total=   8.1s\n",
      "[CV] neuron1=40, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=50, score=0.000, total=   8.2s\n",
      "[CV] neuron1=40, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=50, score=0.000, total=   8.2s\n",
      "[CV] neuron1=40, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=50, score=0.000, total=   8.0s\n",
      "[CV] neuron1=40, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=50, score=0.000, total=   7.9s\n",
      "[CV] neuron1=40, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=50, score=0.000, total=   7.8s\n",
      "[CV] neuron1=40, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=60, score=0.000, total=   7.8s\n",
      "[CV] neuron1=40, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=60, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=60, score=0.000, total=   7.6s\n",
      "[CV] neuron1=40, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=60, score=0.000, total=   7.5s\n",
      "[CV] neuron1=40, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=40, neuron2=60, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=2, score=0.000, total=   7.2s\n",
      "[CV] neuron1=50, neuron2=2 ...........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... neuron1=50, neuron2=2, score=0.000, total=   7.4s\n",
      "[CV] neuron1=50, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=2, score=0.000, total=   7.5s\n",
      "[CV] neuron1=50, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=2, score=0.000, total=   7.5s\n",
      "[CV] neuron1=50, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=2, score=0.000, total=   9.1s\n",
      "[CV] neuron1=50, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=4, score=0.000, total=  14.6s\n",
      "[CV] neuron1=50, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=4, score=0.000, total=  11.3s\n",
      "[CV] neuron1=50, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=4, score=0.000, total=  10.0s\n",
      "[CV] neuron1=50, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=4, score=0.000, total=   7.8s\n",
      "[CV] neuron1=50, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=4, score=0.000, total=   7.8s\n",
      "[CV] neuron1=50, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=8, score=0.000, total=   8.0s\n",
      "[CV] neuron1=50, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=8, score=0.000, total=   8.0s\n",
      "[CV] neuron1=50, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=8, score=0.000, total=   8.2s\n",
      "[CV] neuron1=50, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=8, score=0.000, total=   8.2s\n",
      "[CV] neuron1=50, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=50, neuron2=8, score=0.000, total=   8.1s\n",
      "[CV] neuron1=50, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=20, score=0.000, total=   8.0s\n",
      "[CV] neuron1=50, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=20, score=0.000, total=   7.9s\n",
      "[CV] neuron1=50, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=20, score=0.000, total=   7.7s\n",
      "[CV] neuron1=50, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=20, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=20, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=30, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=30, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=30, score=0.000, total=   7.7s\n",
      "[CV] neuron1=50, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=30, score=0.000, total=   7.4s\n",
      "[CV] neuron1=50, neuron2=30 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=30, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=40, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=40, score=0.000, total=   7.7s\n",
      "[CV] neuron1=50, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=40, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=40, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=40 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=40, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=50, score=0.000, total=   7.7s\n",
      "[CV] neuron1=50, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=50, score=0.000, total=   7.9s\n",
      "[CV] neuron1=50, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=50, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=50, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=50 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=50, score=0.000, total=   7.6s\n",
      "[CV] neuron1=50, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=60, score=0.000, total=   7.7s\n",
      "[CV] neuron1=50, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=60, score=0.000, total=   7.7s\n",
      "[CV] neuron1=50, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=60, score=0.000, total=   7.8s\n",
      "[CV] neuron1=50, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=60, score=0.000, total=   7.8s\n",
      "[CV] neuron1=50, neuron2=60 ..........................................\n",
      "[CV] .............. neuron1=50, neuron2=60, score=0.000, total=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 280 out of 280 | elapsed: 38.0min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "neuron1 = [4,8,16,20,30,40,50]\n",
    "neuron2 = [2,4,8,20,30,40,50,60]\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 60}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10527, 10), (4512, 10), (10527,), (4512,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size =0.3,random_state =42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmizer =RMSprop(0.001)\n",
    "model_new=keras.Sequential([\n",
    "    keras.layers.Dense(4,input_dim =(n_features),activation='relu'),\n",
    "    keras.layers.Dense(2,activation ='relu')\n",
    "])\n",
    "model_new.compile(optimizer =optmizer,loss= 'mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 1s 603us/step - loss: 0.4736 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 1s 652us/step - loss: 0.4736 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 1s 637us/step - loss: 0.4736 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 1s 623us/step - loss: 0.4736 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 1s 625us/step - loss: 0.4736 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 1s 610us/step - loss: 0.4735 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 1s 686us/step - loss: 0.4735 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 1s 616us/step - loss: 0.4735 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 1s 660us/step - loss: 0.4734 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 1s 603us/step - loss: 0.4734 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ad1cf26c8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value =42;\n",
    "import random\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "model_new.fit(X_train, y_train, epochs=10, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 534us/step - loss: 0.4931 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4930703938007355, 0.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
