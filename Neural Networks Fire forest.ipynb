{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Layer,Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv('D:\\\\ExcelR_Assig_PDF\\\\Neural Networks\\\\forestfires.csv')\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF1= DF.iloc[:,2:30]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(DF1)\n",
    "DF_norm = sc.transform(DF1)\n",
    "DF_norm          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  4.98037274e-16, -2.73530281e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -9.55928328e-15,  1.15055466e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  2.58690766e-15, -5.66797432e-17],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -1.84247930e-16,  2.36645381e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -2.30354869e-16,  2.72058887e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.70142521e-17,  8.50237385e-17]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(DF_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.95971390e-33])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = np.cumsum(np.round(var,decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var1,color=\"blue\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                     DF[['size_category']]], axis = 1)\n",
    "finalDf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = finalDf.values\n",
    "X = array[:,0:24]\n",
    "Y = array[:,24]\n",
    "\n",
    "X.reshape(-1,1)\n",
    "Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 1s 5ms/step - loss: 0.6893 - accuracy: 0.5319 - val_loss: 0.6854 - val_accuracy: 0.6090\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6953 - val_loss: 0.6765 - val_accuracy: 0.6474\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.7258 - val_loss: 0.6712 - val_accuracy: 0.6538\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5841 - accuracy: 0.7424 - val_loss: 0.6699 - val_accuracy: 0.6538\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7535 - val_loss: 0.6673 - val_accuracy: 0.6538\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7535 - val_loss: 0.6678 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7645 - val_loss: 0.6644 - val_accuracy: 0.6538\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7645 - val_loss: 0.6668 - val_accuracy: 0.6538\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7645 - val_loss: 0.6696 - val_accuracy: 0.6603\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7645 - val_loss: 0.6711 - val_accuracy: 0.6603\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7673 - val_loss: 0.6739 - val_accuracy: 0.6538\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7673 - val_loss: 0.6743 - val_accuracy: 0.6474\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7673 - val_loss: 0.6778 - val_accuracy: 0.6474\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7701 - val_loss: 0.6782 - val_accuracy: 0.6538\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7701 - val_loss: 0.6800 - val_accuracy: 0.6538\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7701 - val_loss: 0.6817 - val_accuracy: 0.6538\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7701 - val_loss: 0.6841 - val_accuracy: 0.6538\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7729 - val_loss: 0.6809 - val_accuracy: 0.6538\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7756 - val_loss: 0.6837 - val_accuracy: 0.6474\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7729 - val_loss: 0.6832 - val_accuracy: 0.6474\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7784 - val_loss: 0.6797 - val_accuracy: 0.6667\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7756 - val_loss: 0.6838 - val_accuracy: 0.6667\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.6842 - val_accuracy: 0.6795\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7839 - val_loss: 0.6813 - val_accuracy: 0.6859\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.7867 - val_loss: 0.6829 - val_accuracy: 0.6923\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.7950 - val_loss: 0.6821 - val_accuracy: 0.6859\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.7978 - val_loss: 0.6816 - val_accuracy: 0.6859\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8061 - val_loss: 0.6800 - val_accuracy: 0.6731\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8006 - val_loss: 0.6834 - val_accuracy: 0.6538\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8061 - val_loss: 0.6809 - val_accuracy: 0.6538\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8061 - val_loss: 0.6786 - val_accuracy: 0.6474\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8199 - val_loss: 0.6808 - val_accuracy: 0.6474\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8199 - val_loss: 0.6866 - val_accuracy: 0.6474\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8227 - val_loss: 0.6886 - val_accuracy: 0.6538\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8338 - val_loss: 0.6847 - val_accuracy: 0.6667\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8366 - val_loss: 0.6814 - val_accuracy: 0.6667\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8366 - val_loss: 0.6859 - val_accuracy: 0.6538\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8393 - val_loss: 0.6862 - val_accuracy: 0.6603\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8449 - val_loss: 0.6845 - val_accuracy: 0.6410\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8449 - val_loss: 0.6823 - val_accuracy: 0.6218\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8532 - val_loss: 0.6854 - val_accuracy: 0.6474\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8615 - val_loss: 0.6845 - val_accuracy: 0.6282\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8643 - val_loss: 0.6830 - val_accuracy: 0.6218\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8698 - val_loss: 0.6825 - val_accuracy: 0.6282\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.8726 - val_loss: 0.6812 - val_accuracy: 0.6282\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.8892 - val_loss: 0.6803 - val_accuracy: 0.6282\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.8947 - val_loss: 0.6846 - val_accuracy: 0.6282\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.9003 - val_loss: 0.6794 - val_accuracy: 0.6282\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2600 - accuracy: 0.8975 - val_loss: 0.6680 - val_accuracy: 0.6410\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9030 - val_loss: 0.6699 - val_accuracy: 0.6410\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9058 - val_loss: 0.6697 - val_accuracy: 0.6282\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9114 - val_loss: 0.6710 - val_accuracy: 0.6538\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9169 - val_loss: 0.6733 - val_accuracy: 0.6410\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9252 - val_loss: 0.6638 - val_accuracy: 0.6538\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9114 - val_loss: 0.6686 - val_accuracy: 0.6538\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9224 - val_loss: 0.6662 - val_accuracy: 0.6538\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9197 - val_loss: 0.6667 - val_accuracy: 0.6538\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9252 - val_loss: 0.6674 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9307 - val_loss: 0.6644 - val_accuracy: 0.6603\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9197 - val_loss: 0.6597 - val_accuracy: 0.6795\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9418 - val_loss: 0.6600 - val_accuracy: 0.6603\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9446 - val_loss: 0.6637 - val_accuracy: 0.6603\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9418 - val_loss: 0.6635 - val_accuracy: 0.6667\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9418 - val_loss: 0.6665 - val_accuracy: 0.6538\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9557 - val_loss: 0.6672 - val_accuracy: 0.6667\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9474 - val_loss: 0.6719 - val_accuracy: 0.6667\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9557 - val_loss: 0.6678 - val_accuracy: 0.6731\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9529 - val_loss: 0.6741 - val_accuracy: 0.6795\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9640 - val_loss: 0.6819 - val_accuracy: 0.6795\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9557 - val_loss: 0.6693 - val_accuracy: 0.6859\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9612 - val_loss: 0.6596 - val_accuracy: 0.6923\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9640 - val_loss: 0.6720 - val_accuracy: 0.6987\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9584 - val_loss: 0.6681 - val_accuracy: 0.6987\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9640 - val_loss: 0.6746 - val_accuracy: 0.6987\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9668 - val_loss: 0.6584 - val_accuracy: 0.7115\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9640 - val_loss: 0.6645 - val_accuracy: 0.7115\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9695 - val_loss: 0.6639 - val_accuracy: 0.7308\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9640 - val_loss: 0.6535 - val_accuracy: 0.7244\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9668 - val_loss: 0.6691 - val_accuracy: 0.7115\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9612 - val_loss: 0.6691 - val_accuracy: 0.7179\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9695 - val_loss: 0.6728 - val_accuracy: 0.7179\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.9695 - val_loss: 0.6894 - val_accuracy: 0.7115\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9668 - val_loss: 0.6792 - val_accuracy: 0.7115\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9695 - val_loss: 0.6739 - val_accuracy: 0.7179\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9751 - val_loss: 0.6738 - val_accuracy: 0.7308\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9695 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9695 - val_loss: 0.6582 - val_accuracy: 0.7500\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9723 - val_loss: 0.6692 - val_accuracy: 0.7564\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9723 - val_loss: 0.6747 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9723 - val_loss: 0.6650 - val_accuracy: 0.7821\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9723 - val_loss: 0.6671 - val_accuracy: 0.7756\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9695 - val_loss: 0.6683 - val_accuracy: 0.7821\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9723 - val_loss: 0.6797 - val_accuracy: 0.7756\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9751 - val_loss: 0.6718 - val_accuracy: 0.8013\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9668 - val_loss: 0.6790 - val_accuracy: 0.7756\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9751 - val_loss: 0.6820 - val_accuracy: 0.7756\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9723 - val_loss: 0.6938 - val_accuracy: 0.7692\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9723 - val_loss: 0.6856 - val_accuracy: 0.7949\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9751 - val_loss: 0.6884 - val_accuracy: 0.7885\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9723 - val_loss: 0.6910 - val_accuracy: 0.7628\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9723 - val_loss: 0.6853 - val_accuracy: 0.7949\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9723 - val_loss: 0.6955 - val_accuracy: 0.7885\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9778 - val_loss: 0.6855 - val_accuracy: 0.7949\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9834 - val_loss: 0.6909 - val_accuracy: 0.8077\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9778 - val_loss: 0.7051 - val_accuracy: 0.7949\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9806 - val_loss: 0.6997 - val_accuracy: 0.7885\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9806 - val_loss: 0.6976 - val_accuracy: 0.7949\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9861 - val_loss: 0.7090 - val_accuracy: 0.7885\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9861 - val_loss: 0.7131 - val_accuracy: 0.7885\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9778 - val_loss: 0.7247 - val_accuracy: 0.7885\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9889 - val_loss: 0.7137 - val_accuracy: 0.7949\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9861 - val_loss: 0.7240 - val_accuracy: 0.8013\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9861 - val_loss: 0.7304 - val_accuracy: 0.8013\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9751 - val_loss: 0.7325 - val_accuracy: 0.8013\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9889 - val_loss: 0.7456 - val_accuracy: 0.7949\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9834 - val_loss: 0.7434 - val_accuracy: 0.8205\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9889 - val_loss: 0.7417 - val_accuracy: 0.8077\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9917 - val_loss: 0.7579 - val_accuracy: 0.8013\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9861 - val_loss: 0.7474 - val_accuracy: 0.8333\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9861 - val_loss: 0.7650 - val_accuracy: 0.8397\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9945 - val_loss: 0.7635 - val_accuracy: 0.8141\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9861 - val_loss: 0.7729 - val_accuracy: 0.8269\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9917 - val_loss: 0.7828 - val_accuracy: 0.8141\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9861 - val_loss: 0.7762 - val_accuracy: 0.8269\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.7778 - val_accuracy: 0.8269\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9945 - val_loss: 0.7930 - val_accuracy: 0.8333\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9778 - val_loss: 0.7850 - val_accuracy: 0.8397\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9889 - val_loss: 0.7987 - val_accuracy: 0.8205\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9972 - val_loss: 0.7944 - val_accuracy: 0.8397\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9806 - val_loss: 0.8096 - val_accuracy: 0.8205\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9945 - val_loss: 0.8140 - val_accuracy: 0.8397\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9834 - val_loss: 0.8122 - val_accuracy: 0.8462\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9889 - val_loss: 0.8022 - val_accuracy: 0.8397\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.8394 - val_accuracy: 0.8462\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9972 - val_loss: 0.8147 - val_accuracy: 0.8397\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9917 - val_loss: 0.8024 - val_accuracy: 0.8590\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.8132 - val_accuracy: 0.8590\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.8526\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9917 - val_loss: 0.8231 - val_accuracy: 0.8333\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9945 - val_loss: 0.8403 - val_accuracy: 0.8526\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9917 - val_loss: 0.8400 - val_accuracy: 0.8462\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.8430 - val_accuracy: 0.8397\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9945 - val_loss: 0.8699 - val_accuracy: 0.8462\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9917 - val_loss: 0.8556 - val_accuracy: 0.8462\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9972 - val_loss: 0.8663 - val_accuracy: 0.8526\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9945 - val_loss: 0.8607 - val_accuracy: 0.8462\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9972 - val_loss: 0.8739 - val_accuracy: 0.8462\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9945 - val_loss: 0.8681 - val_accuracy: 0.8526\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9945 - val_loss: 0.8781 - val_accuracy: 0.8462\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.8792 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b5633e908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 686us/step - loss: 0.2826 - accuracy: 0.9574\n",
      "accuracy: 95.74%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
